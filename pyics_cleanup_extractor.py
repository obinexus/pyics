#!/usr/bin/env python3
"""
pyics_systematic_cleanup_executor.py
Pyics Systematic Architecture Cleanup Implementation

Engineering Lead: Nnamdi Okpala / OBINexus Computing  
Methodology: Waterfall-based systematic execution
Objective: Resolve domain redundancy and implement single-pass loading

TECHNICAL SPECIFICATIONS:
- Domain consolidation: validation ‚Üí validators, transforms ‚Üí transformations
- Structure flattening: eliminate complex nested patterns
- Single-pass load order: primitives(10) ‚Üí protocols(20) ‚Üí structures(30) ‚Üí ...
- Comprehensive backup and rollback capabilities
- Deterministic execution with validation checkpoints
"""

import os
import sys
import shutil
import json
import ast
from pathlib import Path
from typing import Dict, List, Set, Any, Optional, Tuple
from datetime import datetime
import logging

# Technical Configuration
PROJECT_ROOT = Path.cwd()
PYICS_CORE_DIR = "pyics/core"
BACKUP_ROOT = "systematic_cleanup_backup"

# Systematic execution phases
EXECUTION_PHASES = {
    "phase_1_backup": {
        "priority": 1,
        "description": "Comprehensive backup and structure analysis",
        "dependencies": []
    },
    "phase_2_domain_consolidation": {
        "priority": 2, 
        "description": "Domain redundancy elimination",
        "dependencies": ["phase_1_backup"]
    },
    "phase_3_structure_flattening": {
        "priority": 3,
        "description": "Complex structure elimination",
        "dependencies": ["phase_2_domain_consolidation"]
    },
    "phase_4_load_order_implementation": {
        "priority": 4,
        "description": "Single-pass load order configuration",
        "dependencies": ["phase_3_structure_flattening"]
    },
    "phase_5_validation": {
        "priority": 5,
        "description": "Architecture compliance validation",
        "dependencies": ["phase_4_load_order_implementation"]
    }
}

# Domain transformation specifications
DOMAIN_TRANSFORMATIONS = {
    "validation": {
        "action": "merge",
        "target": "validators",
        "preservation_strategy": "merge_with_documentation"
    },
    "transforms": {
        "action": "eliminate",
        "target": "transformations/legacy_transforms",
        "preservation_strategy": "legacy_archive"
    },
    "logic": {
        "action": "eliminate",
        "target": "DELETE",
        "preservation_strategy": "function_preservation"
    }
}

# Single-pass load order specification
SINGLE_PASS_ARCHITECTURE = {
    "primitives": {"load_order": 10, "priority": 1, "dependencies": []},
    "protocols": {"load_order": 20, "priority": 1, "dependencies": []},
    "structures": {"load_order": 30, "priority": 2, "dependencies": ["primitives", "protocols"]},
    "composition": {"load_order": 40, "priority": 2, "dependencies": ["primitives", "protocols"]},
    "validators": {"load_order": 50, "priority": 3, "dependencies": ["primitives", "protocols", "structures"]},
    "transformations": {"load_order": 60, "priority": 3, "dependencies": ["primitives", "protocols", "structures", "composition"]},
    "registry": {"load_order": 70, "priority": 4, "dependencies": ["primitives", "protocols", "structures", "composition", "validators"]},
    "routing": {"load_order": 80, "priority": 4, "dependencies": ["registry"]},
    "safety": {"load_order": 90, "priority": 5, "dependencies": ["registry", "routing"]}
}

# Complex structure elimination patterns
COMPLEX_ELIMINATION_PATTERNS = [
    "implementations",
    "interfaces", 
    "compliance",
    "contracts",
    "tests"
]

# Logging configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(name)s] - %(message)s',
    handlers=[
        logging.FileHandler('pyics_cleanup.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class PyicsSystematicCleanupExecutor:
    """
    Systematic architecture cleanup executor implementing waterfall methodology
    
    Provides deterministic, phase-based cleanup with comprehensive validation
    and rollback capabilities at each execution checkpoint.
    """
    
    def __init__(self, project_root: Path):
        self.project_root = project_root.resolve()
        self.core_dir = self.project_root / PYICS_CORE_DIR
        self.backup_root = self.project_root / BACKUP_ROOT
        
        self.execution_state = {
            "phase_results": {},
            "rollback_points": [],
            "preserved_content": {},
            "validation_results": {},
            "completion_status": "initialized"
        }
        
        self.discovered_domains = []
        self.structure_analysis = {}
        
    def execute_systematic_cleanup(self) -> Dict[str, Any]:
        """Execute systematic cleanup following waterfall methodology"""
        logger.info("="*80)
        logger.info("PYICS SYSTEMATIC ARCHITECTURE CLEANUP EXECUTION")
        logger.info("Engineering Lead: Nnamdi Okpala / OBINexus Computing")
        logger.info("Methodology: Waterfall-based systematic implementation")
        logger.info("="*80)
        
        try:
            # Execute phases in systematic order
            for phase_name, phase_config in sorted(EXECUTION_PHASES.items(), 
                                                 key=lambda x: x[1]["priority"]):
                logger.info(f"Executing {phase_name}: {phase_config['description']}")
                
                # Validate dependencies
                self._validate_phase_dependencies(phase_name, phase_config)
                
                # Execute phase
                phase_result = self._execute_phase(phase_name, phase_config)
                self.execution_state["phase_results"][phase_name] = phase_result
                
                # Create rollback point
                self._create_phase_rollback_point(phase_name)
                
                # Validate phase completion
                if not phase_result.get("success", False):
                    raise Exception(f"Phase {phase_name} failed: {phase_result.get('error', 'Unknown error')}")
                
                logger.info(f"‚úÖ {phase_name} completed successfully")
            
            self.execution_state["completion_status"] = "success"
            self._generate_completion_report()
            
            return self.execution_state
            
        except Exception as e:
            logger.error(f"Systematic cleanup failed: {e}")
            self.execution_state["completion_status"] = "failed"
            self.execution_state["error"] = str(e)
            self._offer_systematic_rollback()
            return self.execution_state
    
    def _validate_phase_dependencies(self, phase_name: str, phase_config: Dict[str, Any]) -> None:
        """Validate phase dependencies before execution"""
        dependencies = phase_config.get("dependencies", [])
        
        for dependency in dependencies:
            if dependency not in self.execution_state["phase_results"]:
                raise Exception(f"Phase {phase_name} dependency {dependency} not completed")
            
            dep_result = self.execution_state["phase_results"][dependency]
            if not dep_result.get("success", False):
                raise Exception(f"Phase {phase_name} dependency {dependency} failed")
    
    def _execute_phase(self, phase_name: str, phase_config: Dict[str, Any]) -> Dict[str, Any]:
        """Execute individual phase with error handling"""
        try:
            if phase_name == "phase_1_backup":
                return self._execute_backup_phase()
            elif phase_name == "phase_2_domain_consolidation":
                return self._execute_domain_consolidation_phase()
            elif phase_name == "phase_3_structure_flattening":
                return self._execute_structure_flattening_phase()
            elif phase_name == "phase_4_load_order_implementation":
                return self._execute_load_order_implementation_phase()
            elif phase_name == "phase_5_validation":
                return self._execute_validation_phase()
            else:
                raise Exception(f"Unknown phase: {phase_name}")
                
        except Exception as e:
            return {"success": False, "error": str(e), "timestamp": datetime.now().isoformat()}
    
    def _execute_backup_phase(self) -> Dict[str, Any]:
        """Phase 1: Comprehensive backup and structure analysis"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_path = self.backup_root / f"phase_1_backup_{timestamp}"
        backup_path.mkdir(parents=True, exist_ok=True)
        
        # Backup entire core directory
        if self.core_dir.exists():
            core_backup = backup_path / "core_original"
            shutil.copytree(self.core_dir, core_backup)
            logger.info(f"Core directory backed up: {core_backup}")
        
        # Analyze current structure
        self.structure_analysis = self._analyze_current_structure()
        
        # Save analysis to backup
        analysis_file = backup_path / "structure_analysis.json"
        with open(analysis_file, 'w', encoding='utf-8') as f:
            json.dump(self.structure_analysis, f, indent=2)
        
        # Discover domains
        self._discover_domains()
        
        return {
            "success": True,
            "backup_path": str(backup_path),
            "domains_discovered": len(self.discovered_domains),
            "structure_complexity": self.structure_analysis.get("complexity_score", 0),
            "timestamp": datetime.now().isoformat()
        }
    
    def _execute_domain_consolidation_phase(self) -> Dict[str, Any]:
        """Phase 2: Domain redundancy elimination"""
        consolidation_results = {}
        
        for domain_name, transformation_spec in DOMAIN_TRANSFORMATIONS.items():
            domain_path = self.core_dir / domain_name
            
            if not domain_path.exists():
                logger.info(f"Domain {domain_name} not found, skipping")
                continue
            
            try:
                if transformation_spec["action"] == "merge":
                    result = self._execute_domain_merge(domain_name, transformation_spec)
                elif transformation_spec["action"] == "eliminate":
                    result = self._execute_domain_elimination(domain_name, transformation_spec)
                
                consolidation_results[domain_name] = result
                logger.info(f"Domain {domain_name} consolidated successfully")
                
            except Exception as e:
                logger.error(f"Domain {domain_name} consolidation failed: {e}")
                consolidation_results[domain_name] = {"success": False, "error": str(e)}
        
        return {
            "success": True,
            "consolidation_results": consolidation_results,
            "domains_processed": len(consolidation_results),
            "timestamp": datetime.now().isoformat()
        }
    
    def _execute_domain_merge(self, domain_name: str, transformation_spec: Dict[str, Any]) -> Dict[str, Any]:
        """Execute domain merge operation"""
        source_path = self.core_dir / domain_name
        target_domain = transformation_spec["target"]
        target_path = self.core_dir / target_domain
        
        # Ensure target domain exists
        target_path.mkdir(exist_ok=True)
        
        # Create merge documentation
        merge_doc_path = target_path / f"_merged_from_{domain_name}.md"
        with open(merge_doc_path, 'w', encoding='utf-8') as f:
            f.write(f"# Merged Content from {domain_name} Domain\n\n")
            f.write(f"Merged into: {target_domain}\n")
            f.write(f"Merge timestamp: {datetime.now().isoformat()}\n")
            f.write(f"Merge strategy: {transformation_spec['preservation_strategy']}\n\n")
        
        # Preserve and merge content
        merged_files = []
        for py_file in source_path.rglob("*.py"):
            if py_file.name == "__init__.py":
                continue
            
            # Read and document content
            with open(py_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Add to merge documentation
            with open(merge_doc_path, 'a', encoding='utf-8') as f:
                f.write(f"## {py_file.relative_to(source_path)}\n")
                f.write(f"```python\n{content}\n```\n\n")
            
            merged_files.append(str(py_file.relative_to(source_path)))
        
        # Remove source domain
        shutil.rmtree(source_path)
        
        return {
            "success": True,
            "target_domain": target_domain,
            "merged_files": merged_files,
            "merge_documentation": str(merge_doc_path)
        }
    
    def _execute_domain_elimination(self, domain_name: str, transformation_spec: Dict[str, Any]) -> Dict[str, Any]:
        """Execute domain elimination operation"""
        source_path = self.core_dir / domain_name
        target = transformation_spec["target"]
        
        if target == "DELETE":
            # Full elimination with function preservation
            preservation_dir = self.core_dir / f"_preserved_{domain_name}"
            preservation_dir.mkdir(exist_ok=True)
            
            # Preserve functions for manual review
            preserved_functions = self._preserve_domain_functions(source_path, preservation_dir)
            
            # Remove domain
            shutil.rmtree(source_path)
            
            return {
                "success": True,
                "action": "eliminated",
                "preserved_functions": preserved_functions,
                "preservation_location": str(preservation_dir)
            }
        else:
            # Move to legacy location
            target_path = self.core_dir / target
            target_path.mkdir(parents=True, exist_ok=True)
            
            # Move content to legacy location
            for item in source_path.iterdir():
                if item.is_file():
                    shutil.copy2(item, target_path / item.name)
                elif item.is_dir():
                    shutil.copytree(item, target_path / item.name)
            
            # Remove source
            shutil.rmtree(source_path)
            
            return {
                "success": True,
                "action": "moved_to_legacy",
                "legacy_location": str(target_path)
            }
    
    def _execute_structure_flattening_phase(self) -> Dict[str, Any]:
        """Phase 3: Complex structure elimination"""
        flattening_results = {}
        eliminated_count = 0
        
        for domain_name in self.discovered_domains:
            domain_path = self.core_dir / domain_name
            
            if not domain_path.exists():
                continue
            
            domain_eliminations = []
            
            for pattern in COMPLEX_ELIMINATION_PATTERNS:
                pattern_path = domain_path / pattern
                
                if pattern_path.exists():
                    # Preserve content before elimination
                    self._preserve_complex_structure(pattern_path, domain_name, pattern)
                    
                    # Eliminate complex structure
                    shutil.rmtree(pattern_path)
                    domain_eliminations.append(pattern)
                    eliminated_count += 1
                    
                    logger.info(f"Eliminated complex structure: {domain_name}/{pattern}")
            
            if domain_eliminations:
                flattening_results[domain_name] = domain_eliminations
        
        return {
            "success": True,
            "flattening_results": flattening_results,
            "total_eliminations": eliminated_count,
            "timestamp": datetime.now().isoformat()
        }
    
    def _execute_load_order_implementation_phase(self) -> Dict[str, Any]:
        """Phase 4: Single-pass load order implementation"""
        
        # Create IoC registry implementation
        ioc_registry_content = self._generate_ioc_registry()
        ioc_registry_path = self.core_dir / "ioc_registry.py"
        
        with open(ioc_registry_path, 'w', encoding='utf-8') as f:
            f.write(ioc_registry_content)
        
        # Create load order configuration
        load_order_config = {
            "single_pass_architecture": SINGLE_PASS_ARCHITECTURE,
            "implementation_timestamp": datetime.now().isoformat(),
            "methodology": "waterfall_systematic",
            "engineering_lead": "Nnamdi Okpala / OBINexus Computing"
        }
        
        config_path = self.core_dir / "_single_pass_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(load_order_config, f, indent=2)
        
        # Generate standard domain modules for active domains
        generated_modules = self._generate_standard_domain_modules()
        
        return {
            "success": True,
            "ioc_registry_created": str(ioc_registry_path),
            "load_order_config": str(config_path),
            "standard_modules_generated": generated_modules,
            "timestamp": datetime.now().isoformat()
        }
    
    def _execute_validation_phase(self) -> Dict[str, Any]:
        """Phase 5: Architecture compliance validation"""
        validation_results = {
            "domain_compliance": {},
            "load_order_compliance": True,
            "structure_compliance": True,
            "import_compliance": True,
            "issues": []
        }
        
        # Validate each domain
        for domain_name in SINGLE_PASS_ARCHITECTURE.keys():
            domain_path = self.core_dir / domain_name
            
            if domain_path.exists():
                domain_validation = self._validate_domain_compliance(domain_name, domain_path)
                validation_results["domain_compliance"][domain_name] = domain_validation
                
                if not domain_validation["compliant"]:
                    validation_results["issues"].extend(domain_validation["issues"])
        
        # Validate load order dependencies
        load_order_validation = self._validate_load_order_dependencies()
        if not load_order_validation["valid"]:
            validation_results["load_order_compliance"] = False
            validation_results["issues"].extend(load_order_validation["issues"])
        
        # Overall validation status
        overall_success = (
            validation_results["load_order_compliance"] and
            validation_results["structure_compliance"] and
            validation_results["import_compliance"] and
            len(validation_results["issues"]) == 0
        )
        
        return {
            "success": overall_success,
            "validation_results": validation_results,
            "issues_count": len(validation_results["issues"]),
            "timestamp": datetime.now().isoformat()
        }
    
    def _analyze_current_structure(self) -> Dict[str, Any]:
        """Analyze current project structure"""
        structure_data = {
            "domains_found": [],
            "complex_structures": {},
            "total_files": 0,
            "complexity_score": 0
        }
        
        if not self.core_dir.exists():
            return structure_data
        
        for item in self.core_dir.iterdir():
            if item.is_dir() and not item.name.startswith('.'):
                domain_name = item.name
                structure_data["domains_found"].append(domain_name)
                
                # Analyze domain complexity
                domain_complexity = self._analyze_domain_complexity(item)
                structure_data["complex_structures"][domain_name] = domain_complexity
                structure_data["complexity_score"] += domain_complexity["score"]
        
        return structure_data
    
    def _analyze_domain_complexity(self, domain_path: Path) -> Dict[str, Any]:
        """Analyze individual domain complexity"""
        complexity_data = {
            "complex_patterns": [],
            "file_count": 0,
            "depth": 0,
            "score": 0
        }
        
        for pattern in COMPLEX_ELIMINATION_PATTERNS:
            pattern_path = domain_path / pattern
            if pattern_path.exists():
                complexity_data["complex_patterns"].append(pattern)
                complexity_data["score"] += 2  # Penalty for complex patterns
        
        # Calculate depth and file count
        for file_path in domain_path.rglob("*"):
            if file_path.is_file():
                complexity_data["file_count"] += 1
                depth = len(file_path.relative_to(domain_path).parts)
                complexity_data["depth"] = max(complexity_data["depth"], depth)
        
        # Add depth penalty
        if complexity_data["depth"] > 3:
            complexity_data["score"] += complexity_data["depth"] - 3
        
        return complexity_data
    
    def _discover_domains(self) -> None:
        """Discover existing domains in core directory"""
        self.discovered_domains = []
        
        if not self.core_dir.exists():
            return
        
        for item in self.core_dir.iterdir():
            if (item.is_dir() and 
                not item.name.startswith('.') and 
                not item.name.startswith('_') and
                item.name != '__pycache__'):
                self.discovered_domains.append(item.name)
        
        logger.info(f"Discovered domains: {self.discovered_domains}")
    
    def _preserve_domain_functions(self, domain_path: Path, preservation_dir: Path) -> List[Dict[str, Any]]:
        """Preserve functions from domain for manual review"""
        preserved_functions = []
        
        for py_file in domain_path.rglob("*.py"):
            if py_file.name == "__init__.py":
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Analyze and extract functions
                tree = ast.parse(content)
                file_functions = []
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        file_functions.append({
                            "name": node.name,
                            "line": node.lineno,
                            "type": "function"
                        })
                    elif isinstance(node, ast.ClassDef):
                        file_functions.append({
                            "name": node.name,
                            "line": node.lineno,
                            "type": "class"
                        })
                
                if file_functions:
                    # Save preserved file
                    preserved_file = preservation_dir / py_file.name
                    with open(preserved_file, 'w', encoding='utf-8') as f:
                        f.write(f"# Preserved from {domain_path.name}/{py_file.name}\n")
                        f.write(f"# Preservation timestamp: {datetime.now().isoformat()}\n")
                        f.write(f"# Functions found: {len(file_functions)}\n\n")
                        f.write(content)
                    
                    preserved_functions.extend(file_functions)
                
            except Exception as e:
                logger.warning(f"Failed to preserve functions from {py_file}: {e}")
        
        return preserved_functions
    
    def _preserve_complex_structure(self, structure_path: Path, domain_name: str, pattern: str) -> None:
        """Preserve complex structure content before elimination"""
        preservation_dir = self.core_dir / "_preserved_complex_structures"
        preservation_dir.mkdir(exist_ok=True)
        
        preservation_file = preservation_dir / f"{domain_name}_{pattern}_preserved.md"
        
        with open(preservation_file, 'w', encoding='utf-8') as f:
            f.write(f"# Preserved Complex Structure: {domain_name}/{pattern}\n\n")
            f.write(f"Preservation timestamp: {datetime.now().isoformat()}\n")
            f.write(f"Systematic cleanup phase: structure_flattening\n\n")
            
            for py_file in structure_path.rglob("*.py"):
                try:
                    with open(py_file, 'r', encoding='utf-8') as py_f:
                        content = py_f.read()
                    
                    f.write(f"## {py_file.relative_to(structure_path)}\n")
                    f.write(f"```python\n{content}\n```\n\n")
                    
                except Exception as e:
                    f.write(f"## {py_file.relative_to(structure_path)}\n")
                    f.write(f"Error reading file: {e}\n\n")
    
    def _generate_ioc_registry(self) -> str:
        """Generate IoC registry implementation"""
        return '''"""
Pyics Single-Pass IoC Registry
Generated by systematic cleanup execution

Engineering Lead: Nnamdi Okpala / OBINexus Computing
Architecture: Single-pass loading with cost-aware dependency resolution
"""

import json
from typing import Dict, List, Any, Optional
from pathlib import Path

SINGLE_PASS_LOAD_ORDER = {
    "primitives": 10,
    "protocols": 20,
    "structures": 30,
    "composition": 40,
    "validators": 50,
    "transformations": 60,
    "registry": 70,
    "routing": 80,
    "safety": 90
}

class SinglePassRegistry:
    """Single-pass domain registry with cost-aware loading"""
    
    def __init__(self):
        self.loaded_domains = {}
        self.load_performance = {}
        
    def get_load_order(self) -> Dict[str, int]:
        """Get single-pass load order configuration"""
        return SINGLE_PASS_LOAD_ORDER.copy()
    
    def get_load_performance(self) -> Dict[str, Any]:
        """Get load performance metrics"""
        return self.load_performance.copy()
    
    def register_domain(self, domain_name: str, domain_module: Any) -> None:
        """Register domain in single-pass order"""
        if domain_name in SINGLE_PASS_LOAD_ORDER:
            self.loaded_domains[domain_name] = domain_module
        else:
            raise ValueError(f"Domain {domain_name} not in single-pass architecture")
    
    def validate_dependencies(self, domain_name: str) -> bool:
        """Validate domain dependencies are loaded"""
        dependencies = self._get_domain_dependencies(domain_name)
        return all(dep in self.loaded_domains for dep in dependencies)
    
    def _get_domain_dependencies(self, domain_name: str) -> List[str]:
        """Get domain dependencies based on load order"""
        current_order = SINGLE_PASS_LOAD_ORDER.get(domain_name, 0)
        return [
            domain for domain, order in SINGLE_PASS_LOAD_ORDER.items()
            if order < current_order
        ]

# Global registry instance
_registry = SinglePassRegistry()

def get_registry() -> SinglePassRegistry:
    """Get global registry instance"""
    return _registry

def validate_architecture() -> bool:
    """Validate single-pass architecture compliance"""
    try:
        registry = get_registry()
        load_order = registry.get_load_order()
        return len(load_order) > 0
    except Exception:
        return False
'''
    
    def _generate_standard_domain_modules(self) -> Dict[str, List[str]]:
        """Generate standard modules for each domain"""
        generated_modules = {}
        
        standard_modules = [
            "data_types.py",
            "operations.py", 
            "relations.py",
            "config.py",
            "__init__.py",
            "README.md"
        ]
        
        for domain_name in SINGLE_PASS_ARCHITECTURE.keys():
            domain_path = self.core_dir / domain_name
            
            if not domain_path.exists():
                domain_path.mkdir(exist_ok=True)
            
            domain_generated = []
            
            for module_name in standard_modules:
                module_path = domain_path / module_name
                
                if not module_path.exists():
                    self._generate_standard_module(domain_name, module_name, module_path)
                    domain_generated.append(module_name)
            
            if domain_generated:
                generated_modules[domain_name] = domain_generated
        
        return generated_modules
    
    def _generate_standard_module(self, domain_name: str, module_name: str, module_path: Path) -> None:
        """Generate individual standard module"""
        if module_name == "data_types.py":
            content = f'''"""
{domain_name.title()} Domain - Data Types
Generated by systematic cleanup execution

Contains immutable data structures and type definitions for {domain_name} domain.
"""

from typing import Any, Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass(frozen=True)
class {domain_name.title()}Entity:
    """Base {domain_name} domain entity"""
    entity_id: str
    created_at: datetime
    metadata: Dict[str, Any]

def get_domain_metadata() -> Dict[str, Any]:
    """Get {domain_name} domain metadata"""
    return {{
        "domain_name": "{domain_name}",
        "load_order": {SINGLE_PASS_ARCHITECTURE[domain_name]["load_order"]},
        "priority": {SINGLE_PASS_ARCHITECTURE[domain_name]["priority"]},
        "dependencies": {SINGLE_PASS_ARCHITECTURE[domain_name]["dependencies"]},
        "thread_safe": True,
        "generated_by": "systematic_cleanup"
    }}
'''
        elif module_name == "operations.py":
            content = f'''"""
{domain_name.title()} Domain - Operations
Generated by systematic cleanup execution

Contains pure functions and operations for {domain_name} domain.
"""

from typing import Any, Dict, List, Optional
from .data_types import {domain_name.title()}Entity, get_domain_metadata

def create_entity(entity_id: str, **kwargs) -> {domain_name.title()}Entity:
    """Create new {domain_name} entity"""
    from datetime import datetime
    
    return {domain_name.title()}Entity(
        entity_id=entity_id,
        created_at=datetime.now(),
        metadata=kwargs
    )

def validate_entity(entity: {domain_name.title()}Entity) -> bool:
    """Validate {domain_name} entity"""
    return (
        entity.entity_id and
        entity.created_at and
        isinstance(entity.metadata, dict)
    )
'''
        elif module_name == "relations.py":
            content = f'''"""
{domain_name.title()} Domain - Relations
Generated by systematic cleanup execution

Contains relationship definitions and graph operations for {domain_name} domain.
"""

from typing import Any, Dict, List, Optional, Set
from .data_types import {domain_name.title()}Entity

class {domain_name.title()}Relations:
    """Relationship manager for {domain_name} domain"""
    
    def __init__(self):
        self.relationships: Dict[str, Set[str]] = {{}}
    
    def add_relationship(self, source_id: str, target_id: str) -> None:
        """Add relationship between entities"""
        if source_id not in self.relationships:
            self.relationships[source_id] = set()
        self.relationships[source_id].add(target_id)
    
    def get_related(self, entity_id: str) -> Set[str]:
        """Get related entity IDs"""
        return self.relationships.get(entity_id, set())
'''
        elif module_name == "config.py":
            content = f'''"""
{domain_name.title()} Domain - Configuration
Generated by systematic cleanup execution

Contains configuration and settings for {domain_name} domain.
"""

from typing import Any, Dict

# Domain configuration
DOMAIN_CONFIG = {{
    "name": "{domain_name}",
    "load_order": {SINGLE_PASS_ARCHITECTURE[domain_name]["load_order"]},
    "priority": {SINGLE_PASS_ARCHITECTURE[domain_name]["priority"]},
    "dependencies": {SINGLE_PASS_ARCHITECTURE[domain_name]["dependencies"]},
    "thread_safe": True,
    "cache_enabled": True,
    "validation_strict": True
}}

def get_config() -> Dict[str, Any]:
    """Get domain configuration"""
    return DOMAIN_CONFIG.copy()

def update_config(updates: Dict[str, Any]) -> None:
    """Update domain configuration"""
    DOMAIN_CONFIG.update(updates)
'''
        elif module_name == "__init__.py":
            content = f'''"""
{domain_name.title()} Domain
Generated by systematic cleanup execution

Public interface for {domain_name} domain with single-pass loading compliance.
"""

from .data_types import {domain_name.title()}Entity, get_domain_metadata
from .operations import create_entity, validate_entity
from .relations import {domain_name.title()}Relations
from .config import get_config, update_config

__all__ = [
    "{domain_name.title()}Entity",
    "get_domain_metadata",
    "create_entity", 
    "validate_entity",
    "{domain_name.title()}Relations",
    "get_config",
    "update_config"
]

# Domain initialization
def _initialize_domain():
    """Initialize {domain_name} domain"""
    from ..ioc_registry import get_registry
    
    registry = get_registry()
    
    # Validate dependencies are loaded
    if not registry.validate_dependencies("{domain_name}"):
        raise ImportError(f"{domain_name} domain dependencies not satisfied")
    
    # Register domain
    import sys
    current_module = sys.modules[__name__]
    registry.register_domain("{domain_name}", current_module)

# Auto-initialize on import
_initialize_domain()
'''
        elif module_name == "README.md":
            content = f'''# {domain_name.title()} Domain

Generated by systematic cleanup execution for single-pass architecture compliance.

## Overview

The {domain_name} domain provides core functionality for {domain_name}-related operations in the Pyics calendar management system.

## Architecture

- **Load Order**: {SINGLE_PASS_ARCHITECTURE[domain_name]["load_order"]}
- **Priority**: {SINGLE_PASS_ARCHITECTURE[domain_name]["priority"]}
- **Dependencies**: {", ".join(SINGLE_PASS_ARCHITECTURE[domain_name]["dependencies"]) if SINGLE_PASS_ARCHITECTURE[domain_name]["dependencies"] else "None"}

## Modules

- `data_types.py`: Immutable data structures and type definitions
- `operations.py`: Pure functions and domain operations  
- `relations.py`: Relationship definitions and graph operations
- `config.py`: Domain configuration and settings
- `__init__.py`: Public domain interface

## Usage

```python
from pyics.core.{domain_name} import create_entity, get_domain_metadata

# Get domain information
metadata = get_domain_metadata()
print(f"Domain: {{metadata['domain_name']}} (Load Order: {{metadata['load_order']}})")

# Create domain entity
entity = create_entity("test_001", description="Test entity")
print(f"Created entity: {{entity.entity_id}}")
```

## Engineering Lead

Nnamdi Okpala / OBINexus Computing  
Systematic cleanup methodology with waterfall implementation
'''
        
        with open(module_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"Generated standard module: {domain_name}/{module_name}")
    
    def _validate_domain_compliance(self, domain_name: str, domain_path: Path) -> Dict[str, Any]:
        """Validate individual domain compliance"""
        compliance_result = {
            "compliant": True,
            "issues": [],
            "standard_modules": [],
            "missing_modules": []
        }
        
        required_modules = [
            "data_types.py",
            "operations.py",
            "relations.py", 
            "config.py",
            "__init__.py",
            "README.md"
        ]
        
        for module_name in required_modules:
            module_path = domain_path / module_name
            
            if module_path.exists():
                compliance_result["standard_modules"].append(module_name)
            else:
                compliance_result["missing_modules"].append(module_name)
                compliance_result["issues"].append(f"Domain {domain_name} missing {module_name}")
                compliance_result["compliant"] = False
        
        # Check for complex structures
        for pattern in COMPLEX_ELIMINATION_PATTERNS:
            pattern_path = domain_path / pattern
            if pattern_path.exists():
                compliance_result["issues"].append(f"Domain {domain_name} contains complex structure: {pattern}")
                compliance_result["compliant"] = False
        
        return compliance_result
    
    def _validate_load_order_dependencies(self) -> Dict[str, Any]:
        """Validate load order dependency compliance"""
        validation_result = {
            "valid": True,
            "issues": []
        }
        
        for domain_name, config in SINGLE_PASS_ARCHITECTURE.items():
            dependencies = config["dependencies"]
            domain_load_order = config["load_order"]
            
            for dependency in dependencies:
                if dependency not in SINGLE_PASS_ARCHITECTURE:
                    validation_result["issues"].append(f"Domain {domain_name} depends on unknown domain: {dependency}")
                    validation_result["valid"] = False
                    continue
                
                dep_load_order = SINGLE_PASS_ARCHITECTURE[dependency]["load_order"]
                
                if dep_load_order >= domain_load_order:
                    validation_result["issues"].append(
                        f"Load order violation: {domain_name}({domain_load_order}) depends on {dependency}({dep_load_order})"
                    )
                    validation_result["valid"] = False
        
        return validation_result
    
    def _create_phase_rollback_point(self, phase_name: str) -> None:
        """Create rollback point after phase completion"""
        rollback_point = {
            "phase": phase_name,
            "timestamp": datetime.now().isoformat(),
            "structure_snapshot": self._capture_structure_snapshot()
        }
        
        self.execution_state["rollback_points"].append(rollback_point)
    
    def _capture_structure_snapshot(self) -> Dict[str, Any]:
        """Capture current structure snapshot"""
        snapshot = {
            "domains": [],
            "total_files": 0
        }
        
        if not self.core_dir.exists():
            return snapshot
        
        for item in self.core_dir.iterdir():
            if item.is_dir() and not item.name.startswith('.'):
                domain_info = {
                    "name": item.name,
                    "files": [f.name for f in item.rglob("*.py") if f.is_file()]
                }
                snapshot["domains"].append(domain_info)
                snapshot["total_files"] += len(domain_info["files"])
        
        return snapshot
    
    def _generate_completion_report(self) -> None:
        """Generate systematic completion report"""
        report_path = self.project_root / "systematic_cleanup_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# Pyics Systematic Architecture Cleanup Report\n\n")
            f.write(f"**Engineering Lead**: Nnamdi Okpala / OBINexus Computing\n")
            f.write(f"**Methodology**: Waterfall-based systematic implementation\n")
            f.write(f"**Completion Timestamp**: {datetime.now().isoformat()}\n\n")
            
            f.write("## Execution Summary\n\n")
            f.write(f"**Status**: {self.execution_state['completion_status']}\n")
            f.write(f"**Phases Completed**: {len(self.execution_state['phase_results'])}\n")
            f.write(f"**Rollback Points**: {len(self.execution_state['rollback_points'])}\n\n")
            
            f.write("## Phase Results\n\n")
            for phase_name, result in self.execution_state["phase_results"].items():
                f.write(f"### {phase_name}\n")
                f.write(f"- **Status**: {'‚úÖ Success' if result.get('success') else '‚ùå Failed'}\n")
                f.write(f"- **Timestamp**: {result.get('timestamp', 'N/A')}\n")
                
                if 'error' in result:
                    f.write(f"- **Error**: {result['error']}\n")
                
                f.write("\n")
            
            f.write("## Single-Pass Architecture Implementation\n\n")
            f.write("| Domain | Load Order | Priority | Dependencies |\n")
            f.write("|--------|------------|----------|-------------|\n")
            
            for domain_name, config in SINGLE_PASS_ARCHITECTURE.items():
                deps = ", ".join(config["dependencies"]) if config["dependencies"] else "None"
                f.write(f"| {domain_name} | {config['load_order']} | {config['priority']} | {deps} |\n")
            
            f.write("\n## Preservation Locations\n\n")
            f.write("- **Backup Root**: `systematic_cleanup_backup/`\n")
            f.write("- **Preserved Logic**: `pyics/core/_preserved_logic/`\n")
            f.write("- **Complex Structures**: `pyics/core/_preserved_complex_structures/`\n")
            f.write("- **Merge Documentation**: Domain-specific merge records\n\n")
            
            f.write("## Next Steps\n\n")
            f.write("1. Review preserved functions for manual integration\n")
            f.write("2. Test single-pass loading with new architecture\n")
            f.write("3. Update import statements in existing code\n")
            f.write("4. Implement domain-specific business logic\n")
            f.write("5. Establish CI/CD validation for architecture compliance\n")
        
        logger.info(f"Completion report generated: {report_path}")
    
    def _offer_systematic_rollback(self) -> None:
        """Offer systematic rollback options"""
        logger.error("Systematic cleanup failed. Rollback options available:")
        logger.error(f"Backup root: {self.backup_root}")
        
        for i, rollback_point in enumerate(self.execution_state["rollback_points"]):
            logger.error(f"Rollback point {i+1}: {rollback_point['phase']} at {rollback_point['timestamp']}")

def main():
    """Main execution function"""
    executor = PyicsSystematicCleanupExecutor(PROJECT_ROOT)
    results = executor.execute_systematic_cleanup()
    
    print("="*80)
    print("PYICS SYSTEMATIC CLEANUP EXECUTION REPORT")
    print("="*80)
    print(f"Status: {results['completion_status']}")
    print(f"Phases completed: {len(results['phase_results'])}")
    
    for phase_name, result in results["phase_results"].items():
        status_icon = "‚úÖ" if result.get("success") else "‚ùå"
        print(f"  {status_icon} {phase_name}: {result.get('timestamp', 'N/A')}")
    
    if results["completion_status"] == "success":
        print("\nüéâ SYSTEMATIC CLEANUP COMPLETED SUCCESSFULLY!")
        print("üìä Single-pass architecture implemented")
        print("üßπ Domain redundancy eliminated") 
        print("üìÅ Complex structures flattened")
        print("‚ö° Load order configuration established")
        print("üìã Standard domain modules generated")
        
        print("\nüìç PRESERVED CONTENT LOCATIONS:")
        print("   ‚Ä¢ Backup: systematic_cleanup_backup/")
        print("   ‚Ä¢ Logic: pyics/core/_preserved_logic/")
        print("   ‚Ä¢ Complex: pyics/core/_preserved_complex_structures/")
        
        print("\nüîß TECHNICAL VALIDATION:")
        print("   ‚Ä¢ Import: python -c 'from pyics.core.ioc_registry import get_registry; print(\"‚úÖ Registry loaded\")'")
        print("   ‚Ä¢ Architecture: python -c 'from pyics.core.ioc_registry import validate_architecture; print(\"‚úÖ Valid\" if validate_architecture() else \"‚ùå Invalid\")'")
        
    else:
        print("\n‚ùå SYSTEMATIC CLEANUP FAILED")
        print(f"Error: {results.get('error', 'Unknown error')}")
        print("Check logs and backup for recovery options")
    
    print("="*80)
    
    sys.exit(0 if results["completion_status"] == "success" else 1)

if __name__ == "__main__":
    main()
